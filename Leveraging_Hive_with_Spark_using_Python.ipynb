{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Leveraging Hive with Spark using Python.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6ZlLh-jsMU1",
        "outputId": "62a5fe3d-1f5b-4ca2-aee2-22b860b5a9fc"
      },
      "source": [
        "pip install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 71kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 42.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=bd53a8d6cf86a273977dfdd8aabb727ffcbfa08d3e22ac776be59f550c8011e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBCOICV0suGx"
      },
      "source": [
        "we will see how to use Spark with Hive, particularly:\n",
        "\n",
        "– how to create and use Hive databases\n",
        "\n",
        "– how to create Hive tables\n",
        "\n",
        "– how to load data to Hive tables\n",
        "\n",
        "– how to insert data into Hive tables\n",
        "\n",
        "– how to read data from Hive tables\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t06Z6p_XsqgB",
        "outputId": "af71c8cd-beba-4efa-f685-8d9cf565e98a"
      },
      "source": [
        "import os\n",
        "os.listdir(os.getcwd())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gRzeQH5sxW7"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.enableHiveSupport().getOrCreate()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAZeNxSZs0za",
        "outputId": "6257de7f-4579-421c-b966-081393afa22b"
      },
      "source": [
        "os.listdir(os.getcwd())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLNY7FNWs3oz",
        "outputId": "bf542683-9504-40d6-fcb9-5459ea6b185e"
      },
      "source": [
        "spark.sql('show databases').show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|namespace|\n",
            "+---------+\n",
            "|  default|\n",
            "+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ogAAHI4s--e",
        "outputId": "dd369b8d-ef5c-4573-9a8a-13f71b9e0d50"
      },
      "source": [
        "spark.sql('show tables').show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+---------+-----------+\n",
            "|database|tableName|isTemporary|\n",
            "+--------+---------+-----------+\n",
            "+--------+---------+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvWxwLgstVgN"
      },
      "source": [
        "We can see the functions in Spark.SQL using the command below.\n",
        " At the time of this writing, we have about following functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKcn2-0ntFdZ",
        "outputId": "1f676f7e-bb63-427a-9f95-ef9faa8e266f"
      },
      "source": [
        "fncs =  spark.sql('show functions').collect()\n",
        "len(fncs)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "351"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prhII0zbtIjl",
        "outputId": "3c10bee7-087b-48d1-8829-01b027b5b3ee"
      },
      "source": [
        "for i in fncs[100:111]:\n",
        "    print(i[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "date_part\n",
            "date_sub\n",
            "date_trunc\n",
            "datediff\n",
            "day\n",
            "dayofmonth\n",
            "dayofweek\n",
            "dayofyear\n",
            "decimal\n",
            "decode\n",
            "degrees\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7eWhbNptjKL"
      },
      "source": [
        "We can see what a function is used for and what the arguments are as below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2g90ODgjtQkB",
        "outputId": "4e291b45-4f34-48a2-82a9-c54330f9c5ad"
      },
      "source": [
        "spark.sql(\"describe function instr\").show(truncate = False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------------------------------------------------------------------------------+\n",
            "|function_desc                                                                                        |\n",
            "+-----------------------------------------------------------------------------------------------------+\n",
            "|Function: instr                                                                                      |\n",
            "|Class: org.apache.spark.sql.catalyst.expressions.StringInstr                                         |\n",
            "|Usage: instr(str, substr) - Returns the (1-based) index of the first occurrence of `substr` in `str`.|\n",
            "+-----------------------------------------------------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eH7iI3fBtd06",
        "outputId": "9d573b60-1dc5-4339-9d2b-7ab29b4441c5"
      },
      "source": [
        "spark.sql('create database movies')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeYKwjhOtxRs",
        "outputId": "86dca3f3-e902-489d-99e9-b8b5cd68b94c"
      },
      "source": [
        "spark.sql('show databases').show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|namespace|\n",
            "+---------+\n",
            "|  default|\n",
            "|   movies|\n",
            "+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbqDYpadt0Mu",
        "outputId": "fc5c3311-a8c4-4ff6-d578-17c24eb26eba"
      },
      "source": [
        "! wget http://files.grouplens.org/datasets/movielens/ml-latest.zip"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-02 15:34:28--  http://files.grouplens.org/datasets/movielens/ml-latest.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 277113433 (264M) [application/zip]\n",
            "Saving to: ‘ml-latest.zip’\n",
            "\n",
            "ml-latest.zip       100%[===================>] 264.28M  78.0MB/s    in 3.6s    \n",
            "\n",
            "2021-05-02 15:34:32 (73.4 MB/s) - ‘ml-latest.zip’ saved [277113433/277113433]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkyQDyunyum-"
      },
      "source": [
        "!unzip /content/ml-latest.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-rU0ravt3ej",
        "outputId": "1facfdfe-d889-4ee1-e478-dc29a8507b1b"
      },
      "source": [
        "spark.sql('use movies')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ece4Ifg-t_2R"
      },
      "source": [
        "The movies dataset has movieId, title and genres fields. \n",
        "\n",
        "The rating dataset, on the other hand, as userId, movieID, rating and timestamp fields. \n",
        "\n",
        "Now, let’s create the tables.\n",
        "\n",
        "Please refer to the Hive manual for details on how to create tables and load/insert data into the tables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6IvGjCat7tz",
        "outputId": "d8555436-ee25-4eb3-c4b7-30b6e5655969"
      },
      "source": [
        "spark.sql('create table movies \\\n",
        "         (movieId int,title string,genres string) \\\n",
        "         row format delimited fields terminated by \",\"\\\n",
        "         stored as textfile')                                              # in textfile format\n",
        "\n",
        "spark.sql(\"create table ratings\\\n",
        "           (userId int,movieId int,rating float,timestamp string)\\\n",
        "           stored as ORC\" )                                                # in ORC format"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYtgdRwnuQ2n"
      },
      "source": [
        "Let’s create another table in AVRO format. \n",
        "\n",
        "We will insert count of movies by generes into it later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY5FhpHNuMJt",
        "outputId": "79f7e057-6752-44a1-f5cf-afe8c5f1c872"
      },
      "source": [
        "spark.sql(\"create table genres_by_count\\\n",
        "           ( genres string,count int)\\\n",
        "           stored as AVRO\" )                                               # in AVRO format"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwkHu8sXuThc",
        "outputId": "d472f6a7-35fa-4ce8-b99f-66026ba828bd"
      },
      "source": [
        "spark.sql(\"show tables\").show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+---------------+-----------+\n",
            "|database|      tableName|isTemporary|\n",
            "+--------+---------------+-----------+\n",
            "|  movies|genres_by_count|      false|\n",
            "|  movies|         movies|      false|\n",
            "|  movies|        ratings|      false|\n",
            "+--------+---------------+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Kx81QNNuWsE",
        "outputId": "9a3eeb9a-66e3-4fc8-8a6c-7a3c37e4feef"
      },
      "source": [
        "spark.sql(\"describe formatted ratings\").show(truncate = False)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------------+------------------------------------------------+-------+\n",
            "|col_name                    |data_type                                       |comment|\n",
            "+----------------------------+------------------------------------------------+-------+\n",
            "|userId                      |int                                             |null   |\n",
            "|movieId                     |int                                             |null   |\n",
            "|rating                      |float                                           |null   |\n",
            "|timestamp                   |string                                          |null   |\n",
            "|                            |                                                |       |\n",
            "|# Detailed Table Information|                                                |       |\n",
            "|Database                    |movies                                          |       |\n",
            "|Table                       |ratings                                         |       |\n",
            "|Owner                       |root                                            |       |\n",
            "|Created Time                |Sun May 02 15:35:54 UTC 2021                    |       |\n",
            "|Last Access                 |UNKNOWN                                         |       |\n",
            "|Created By                  |Spark 3.1.1                                     |       |\n",
            "|Type                        |MANAGED                                         |       |\n",
            "|Provider                    |hive                                            |       |\n",
            "|Table Properties            |[transient_lastDdlTime=1619969754]              |       |\n",
            "|Location                    |file:/content/spark-warehouse/movies.db/ratings |       |\n",
            "|Serde Library               |org.apache.hadoop.hive.ql.io.orc.OrcSerde       |       |\n",
            "|InputFormat                 |org.apache.hadoop.hive.ql.io.orc.OrcInputFormat |       |\n",
            "|OutputFormat                |org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat|       |\n",
            "|Storage Properties          |[serialization.format=1]                        |       |\n",
            "+----------------------------+------------------------------------------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFZVKjvDubR6",
        "outputId": "095b329f-2233-4688-b89e-857f29c3330f"
      },
      "source": [
        "spark.sql(\"load data local inpath '/content/ml-latest.zip' overwrite into table movies\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsjfMwOIvmlE"
      },
      "source": [
        "from pyspark.sql.types import *\n",
        "schema = StructType([\n",
        "             StructField('userId', IntegerType()),\n",
        "             StructField('movieId', IntegerType()),\n",
        "             StructField('rating', DoubleType()),\n",
        "             StructField('timestamp', StringType())\n",
        "            ])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Pl8aUBAvvwE"
      },
      "source": [
        "ratings_df = spark.read.csv(\"/content/ml-latest/ratings.csv\", schema = schema, header = True)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rX5Zb_Qwf91",
        "outputId": "3bab0177-f2ba-4416-8012-be1c2efe0821"
      },
      "source": [
        "ratings_df.show(5)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+------+----------+\n",
            "|userId|movieId|rating| timestamp|\n",
            "+------+-------+------+----------+\n",
            "|     1|    307|   3.5|1256677221|\n",
            "|     1|    481|   3.5|1256677456|\n",
            "|     1|   1091|   1.5|1256677471|\n",
            "|     1|   1257|   4.5|1256677460|\n",
            "|     1|   1449|   4.5|1256677264|\n",
            "+------+-------+------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bL3R4BUwwiQC",
        "outputId": "d350f38c-3e7e-401b-c5d5-58ad46afc6f7"
      },
      "source": [
        "ratings_df.printSchema()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- userId: integer (nullable = true)\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            " |-- timestamp: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7F8apeczA0n"
      },
      "source": [
        "The second option to create a data frame is to read it in as RDD and change it to data frame by using the toDF data frame function or createDataFrame from SparkSession. Remember, we have to use the Row function from pyspark.sql to use toDF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo5rnCU2xeZf"
      },
      "source": [
        "from pyspark.sql import Row\n",
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "conf = SparkConf().setMaster(\"local[*]\")\n",
        "sc = SparkContext.getOrCreate(conf)\n",
        "\n",
        "rdd = sc.textFile(\"/content/ml-latest/ratings.csv\")\n",
        "header = rdd.first()\n",
        "ratings_df2 = rdd.filter(lambda line: line != header).map(lambda line: Row(userId = int(line.split(\",\")[0]),\n",
        "                                                                     movieId = int(line.split(\",\")[1]),\n",
        "                                                                     rating = float(line.split(\",\")[2]),\n",
        "                                                                     timestamp = line.split(\",\")[3]\n",
        "                                                                    )).toDF()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K59_e3b3y9lA"
      },
      "source": [
        "# another way\n",
        "rdd2 = rdd.filter(lambda line: line != header).map(lambda line:line.split(\",\"))\n",
        "ratings_df2_b =spark.createDataFrame(rdd2, schema = schema)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kU2t1ejzEvH",
        "outputId": "af14c652-1fc4-49ae-cee1-2a79cf181cd7"
      },
      "source": [
        "ratings_df2.printSchema()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- userId: long (nullable = true)\n",
            " |-- movieId: long (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            " |-- timestamp: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Qm9ciMWzJlF",
        "outputId": "3d1038dc-c0e7-4314-eaf6-0e92ed756f8c"
      },
      "source": [
        "ratings_df2.show(5)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+------+----------+\n",
            "|userId|movieId|rating| timestamp|\n",
            "+------+-------+------+----------+\n",
            "|     1|    307|   3.5|1256677221|\n",
            "|     1|    481|   3.5|1256677456|\n",
            "|     1|   1091|   1.5|1256677471|\n",
            "|     1|   1257|   4.5|1256677460|\n",
            "|     1|   1449|   4.5|1256677264|\n",
            "+------+-------+------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjEbot2lzhRM",
        "outputId": "c3505125-31d0-454d-e9a2-94ee95f20fa7"
      },
      "source": [
        "spark.sql(\"load data local inpath '/content/ml-latest/movies.csv' overwrite into table movies\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfdF7RU3zPKf",
        "outputId": "789fd87f-f5d0-4bf8-d1d8-404fc372ba1e"
      },
      "source": [
        "spark.sql(\"select * from movies limit 10\").show(truncate = False)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------------------------------+-------------------------------------------+\n",
            "|movieId|title                             |genres                                     |\n",
            "+-------+----------------------------------+-------------------------------------------+\n",
            "|null   |title                             |genres                                     |\n",
            "|1      |Toy Story (1995)                  |Adventure|Animation|Children|Comedy|Fantasy|\n",
            "|2      |Jumanji (1995)                    |Adventure|Children|Fantasy                 |\n",
            "|3      |Grumpier Old Men (1995)           |Comedy|Romance                             |\n",
            "|4      |Waiting to Exhale (1995)          |Comedy|Drama|Romance                       |\n",
            "|5      |Father of the Bride Part II (1995)|Comedy                                     |\n",
            "|6      |Heat (1995)                       |Action|Crime|Thriller                      |\n",
            "|7      |Sabrina (1995)                    |Comedy|Romance                             |\n",
            "|8      |Tom and Huck (1995)               |Adventure|Children                         |\n",
            "|9      |Sudden Death (1995)               |Action                                     |\n",
            "+-------+----------------------------------+-------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I9fjYIGz0Zo",
        "outputId": "0e09ccd4-2b4b-4d3c-8012-594100711482"
      },
      "source": [
        "spark.sql(\"select genres, count(*) as count from movies\\\n",
        "          group by genres\\\n",
        "          having count(*) > 500 \\\n",
        "          order by count desc\").show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|              genres|count|\n",
            "+--------------------+-----+\n",
            "|               Drama| 7069|\n",
            "|              Comedy| 4735|\n",
            "|  (no genres listed)| 4135|\n",
            "|         Documentary| 3777|\n",
            "|        Comedy|Drama| 1879|\n",
            "|       Drama|Romance| 1754|\n",
            "|      Comedy|Romance| 1323|\n",
            "|              Horror| 1308|\n",
            "|Comedy|Drama|Romance|  856|\n",
            "|      Drama|Thriller|  736|\n",
            "|         Crime|Drama|  734|\n",
            "|            Thriller|  732|\n",
            "|     Horror|Thriller|  692|\n",
            "|           Animation|  595|\n",
            "|           Drama|War|  519|\n",
            "+--------------------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_iXPaR_0K4I",
        "outputId": "0e079c7e-148f-42d8-f3e1-d0ddeb86c0db"
      },
      "source": [
        "spark.sql(\"insert into table genres_by_count \\\n",
        "          select genres, count(*) as count from movies\\\n",
        "          group by genres\\\n",
        "          having count(*) >= 500 \\\n",
        "          order by count desc\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOPx6-9A0RP6",
        "outputId": "eb907e2b-5809-42a1-c6c8-e46587f97a4f"
      },
      "source": [
        "spark.sql(\"select * from genres_by_count order by count desc limit 3\").show()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------+-----+\n",
            "|            genres|count|\n",
            "+------------------+-----+\n",
            "|             Drama| 7069|\n",
            "|            Comedy| 4735|\n",
            "|(no genres listed)| 4135|\n",
            "+------------------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQTIOaMe0TwV",
        "outputId": "d384767d-59c6-4a38-9545-dc431a08ed80"
      },
      "source": [
        "schema = StructType([\n",
        "             StructField('userId', IntegerType()),\n",
        "             StructField('movieId', IntegerType()),\n",
        "             StructField('tag', StringType()),\n",
        "             StructField('timestamp', StringType())\n",
        "            ])\n",
        "\n",
        "tags_df = spark.read.csv(\"/content/ml-latest/tags.csv\", schema = schema, header = True)\n",
        "tags_df.printSchema()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- userId: integer (nullable = true)\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- tag: string (nullable = true)\n",
            " |-- timestamp: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUp0ljw8A1LS"
      },
      "source": [
        "Next, register the dataframe as temporary table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjxnpqhxAxKy"
      },
      "source": [
        "tags_df.registerTempTable('tags_df_table')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I5QXhebA2wp",
        "outputId": "239f7d87-d67e-48ac-a89b-008aa20051a2"
      },
      "source": [
        "spark.sql('show tables').show()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+---------------+-----------+\n",
            "|database|      tableName|isTemporary|\n",
            "+--------+---------------+-----------+\n",
            "|  movies|genres_by_count|      false|\n",
            "|  movies|         movies|      false|\n",
            "|  movies|        ratings|      false|\n",
            "|        |  tags_df_table|       true|\n",
            "+--------+---------------+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAbH7nt6A_XY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}